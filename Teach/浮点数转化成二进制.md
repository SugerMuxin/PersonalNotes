​

一个int类型表示的整数值是 -2^31 ~ 2^31-1

32位二进制表示 11111111111111111111111111111111  ~ 01111111111111111111111111111111

类似整数联想到浮点数是怎么表示的呢？最初正常人可能为这样想的

![](https://i-blog.csdnimg.cn/blog_migrate/98ef37616b01a7287f8af7c3532dd8ba.bmp)![](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw== "点击并拖拽以移动")​编辑

但是这样好像表示的数也太小了，精确度也贼低。看看科学家的设计吧

![](https://i-blog.csdnimg.cn/blog_migrate/2480a2cae258fbfb7d16d70ddedf5af5.bmp)![](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw== "点击并拖拽以移动")​编辑

依次为  符号位  阶码位  尾数位   接下来怎么说呢？还是看个例子吧

19.2转化为二进制  这里以32位为例了。64位类推  就是太长了。（整数部除2取整，小数部分乘2取整（>1的时候舍弃整数位）直到小数位为0或者超过表示范围时候）

19.2----->    19                      .2

转化如图       00010011           .00110011001100110011....

![](https://i-blog.csdnimg.cn/blog_migrate/7ff4dfb69ec54d215a9a6ba71bb767d3.bmp)![](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw== "点击并拖拽以移动")​编辑

编译器正确转化后在存储中是怎么表示的呢？先看下正确的答案。

0  10000011    00110011001100110011010

首先0符号位没意见

其次是阶码位     也就是多少次方了啦 。10011.001100110011....是可以转化为  1.0011001100110011.... *2^4 或者0.1001100110011...*2^5.    

这个4或者是5就是阶码，那阶码位也应该是  00000100 或者  00000101 啊  怎么会是 10000011 呢？

       这个就是科学家设计上的哲学了。因为模仿10进制的习惯方式，小数点的第一位必须是非0数，那么在二进制中非0那就只能是1了。也就是第一位必然是1，那么编译器就选择了 1.001100110011...*2^4这种设计，于是呢所有的浮点数九转化成  1.AAAAAA....*2^n这种表示方式，于是就产生了两个问题。第一个呢，既然所有浮点数的尾数都是1.AAAAA....这种格式，那么计算机在储存的时候是不是可以拿掉这个1呢，取数据的时候就加上这个1，这样就节约了一个宝贵的位，对不对。完美吧。还是有瑕疵的，那么0怎么表示呢，1.AAAA这也没法表示0啊，于是编译器就规定了，当尾数位1.000...阶码为-127就表示0.

即  0   11111111    0000000000000000000000  .  看上去是不是有一点点的不舒服，是的就是这串  11111111  看着好想变成 00000000 啊。那每个阶码都规定+127不就得了。 那么0就变成了  0 00000000  000000000000000000000  perfect对不对

于是19.2 的阶码4+127就变成了  10000011   尾数1.001100110011...舍弃第一个1 就变成了00110011001100110011010（23位）

值得注意的一个点是尾数的后三位变成了010 为什么不是001呢 。四舍五入四舍五入恍然大悟了吧  0011 舍弃最后一个1需要进1 就变成了010

64位的也是这样的就是位数不同

​